{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "from pathlib import Path\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import spacy\r\n",
        "\r\n",
        "%load_ext nb_black"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nb_black extension is already loaded. To reload it, use:\n",
            "  %reload_ext nb_black\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"from pathlib import Path\\r\\n\\r\\nimport pandas as pd\\r\\nimport spacy\\r\\n\\r\\n%load_ext nb_black\";\n                var nbb_formatted_code = \"from pathlib import Path\\n\\nimport pandas as pd\\nimport spacy\\n\\n%load_ext nb_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "id": "5AHZulflnLPY",
        "gather": {
          "logged": 1627681450806
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install trained models\r\n",
        "\r\n",
        "- This should be done in Dockerfile or dev/prod environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install spacy\\results\\packages-full\\en_textcat-2.0.0.tar.gz"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install spacy\\results\\packages-simple\\en_textcat_simple-2.0.0.tar.gz"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "tmYjYPrbnLQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read example JSON file\r\n",
        "\r\n",
        "- Parse out all the features\r\n",
        "    - `category_level_1`: string category\r\n",
        "    - `category_level_2`: string category\r\n",
        "    - `regulated_product_name`: string\r\n",
        "    - `ingredients`: list of strings. Join with '. '\r\n",
        "    - `storage_env`: string category\r\n",
        "    - `pack_type`: string category\r\n",
        "    - `cooking_type`: a list of categories that only exists if there are cooking types. If it does exist, concatenate items with '. ', otherwise, return 'None'\r\n",
        "    - `text`: concatenated from all above features"
      ],
      "metadata": {
        "id": "Mf5OhM89nLQa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df = pd.read_json(\r\n",
        "    Path(\r\n",
        "        'data',\r\n",
        "        'trial-json-products.json',\r\n",
        "    ),\r\n",
        "    orient='records',\r\n",
        "    encoding='utf-16',\r\n",
        "    lines=False,\r\n",
        ").set_index(\r\n",
        "    'pvid',\r\n",
        ").sort_index(\r\n",
        "    ascending=True,\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "qXGDK_nNnLQb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df['category_level_1'] = df['categories'].apply(\r\n",
        "    lambda\r\n",
        "    c: c[0]['description'],\r\n",
        ")\r\n",
        "\r\n",
        "df['category_level_2'] = df['categories'].apply(\r\n",
        "    lambda\r\n",
        "    c: c[1]['description'],\r\n",
        ")\r\n",
        "\r\n",
        "df['regulated_product_name'] = df['languages'].apply(\r\n",
        "    lambda\r\n",
        "    c: c[0]['groupingSets'][0]['attributes']['regulatedProductName']\r\n",
        ")\r\n",
        "\r\n",
        "df['ingredients'] = df['languages'].apply(\r\n",
        "    lambda\r\n",
        "    c: '.'.join(\r\n",
        "        c[0]['groupingSets'][0]['attributes']['ingredients']\r\n",
        "    )\r\n",
        ")\r\n",
        "\r\n",
        "df['storage_env'] = df['languages'].apply(\r\n",
        "    lambda\r\n",
        "    c: c[0]['groupingSets'][0]['attributes']['storageType'][0]\r\n",
        "    ['lookupValue']\r\n",
        ")\r\n",
        "\r\n",
        "df['pack_type'] = df['languages'].apply(\r\n",
        "    lambda\r\n",
        "    c: c[0]['groupingSets'][0]['attributes']['packType'][0]\r\n",
        "    ['lookupValue']\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "def parse_cooking_guidelines(c):\r\n",
        "    try:\r\n",
        "        guidelines = [\r\n",
        "            item['nameValue']\r\n",
        "            for item in c[0]['groupingSets'][0]['attributes']\r\n",
        "            ['cookingGuidelines']\r\n",
        "        ]\r\n",
        "        return '. '.join(set(guidelines))\r\n",
        "\r\n",
        "    except KeyError:\r\n",
        "        return 'None'\r\n",
        "\r\n",
        "\r\n",
        "df['cooking_type'] = df['languages'].apply(\r\n",
        "    parse_cooking_guidelines\r\n",
        ")\r\n",
        "\r\n",
        "df = df[[\r\n",
        "    'category_level_1',\r\n",
        "    'category_level_2',\r\n",
        "    'regulated_product_name',\r\n",
        "    'ingredients',\r\n",
        "    'storage_env',\r\n",
        "    'pack_type',\r\n",
        "    'cooking_type',\r\n",
        "]]\r\n",
        "\r\n",
        "df['text'] = df.apply(\r\n",
        "    lambda s: '. '.join(s[s.notna()]),\r\n",
        "    axis=1,\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "i5cAtxbhnLQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### - Load best trained model"
      ],
      "metadata": {
        "id": "vZhkwNA0nLQi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "nlp = spacy.load('en_textcat')\r\n",
        "# nlp = spacy.load('en_textcat_simple')"
      ],
      "outputs": [],
      "metadata": {
        "id": "mgq8re2NnLQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### - Get the category with the highest score"
      ],
      "metadata": {
        "id": "aI4G-w0UnLQn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def predict(text):\r\n",
        "    doc = nlp(text)\r\n",
        "    \r\n",
        "    return max(\r\n",
        "        doc.cats,\r\n",
        "        key=lambda key: doc.cats[key],\r\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "OlY5fI2WnLQo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df['predict'] = df['text'].apply(predict)\r\n",
        "df.head()"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit ('.venv')"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "model.ipynb",
      "provenance": []
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "interpreter": {
      "hash": "506541454f2e71c9fdce11a02307324979c166298fc178c1da6e1bfef7c64bca"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}